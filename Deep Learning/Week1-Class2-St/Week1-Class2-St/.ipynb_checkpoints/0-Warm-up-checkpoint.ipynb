{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data size is: (908, 6)\n",
      "Output range=[0.053,9.612]\n"
     ]
    }
   ],
   "source": [
    "# import data\n",
    "import pandas as pd\n",
    "\n",
    "colnames = ['CIC0', 'SM1_Dz(Z)', 'GATS1i', 'NdsCH', 'NdssC','MLOGP', 'LC50']\n",
    "data = pd.read_csv('0-fish_toxicity.csv', sep=';', names=colnames)\n",
    "X = data.drop('LC50', axis=1)\n",
    "y = data['LC50']\n",
    "\n",
    "# Print the sizes of the dataset\n",
    "print('The data size is:',X.shape)\n",
    "\n",
    "# print output range (min and max), just to determine if the model should be a classification or regression\n",
    "# In this example, let us not split data into train and test datasets\n",
    "print('Output range=[{},{}]'.format(min(y),max(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Step:\n",
    "Create the function that returns the keras model, use one input layer with 8 nodes and one output layer with a single node Use `mean_squared_error` for loss and `adam` for optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Step:\n",
    "Build the scikit-Learn interface for the keras model. Use 100 epochs, and a batch size of 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the scikit-Learn interface for the keras model\n",
    "# Use 100 epochs, and a batch size of 20\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow import random\n",
    "import numpy as np\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Step:\n",
    "Define the iterator to perform 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Step:\n",
    "Perform cross validation on X, y, and assign the result of the cross validation to a `results` variable and print the mean of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Step:\n",
    "Create the functions that returns the keras models, \n",
    "- model1: \n",
    "   - Use one input layer with 4 nodes and one output layer with a single node\n",
    "   - Use `mean_squared_error` for loss and `adam` for optimizer\n",
    "- model2: \n",
    "   - Use one input layer with 8 nodes and one output layer with a single node\n",
    "   - Use `mean_squared_error` for loss and `adam` for optimizer\n",
    "- model3:\n",
    "   - Use one input layer with 4 nodes, one hidden layer of 2 nodes, and one output layer with a single node\n",
    "   - Use `mean_squared_error` for loss and `adam` for optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Step:\n",
    "Perform cross validation on each model, you can create an empty list for results, i.e., `results=[]`, and\n",
    "another list for the three models you built. you can iterate through the three models in a for loop and record the results. Print the cross validation scores for three models one by one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import random \n",
    "import numpy as np\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "random.set_seed(seed)\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Step:\n",
    "Create a new results list. Loop over pairs of epochs and batch_size for the second model you created above. Print cross validation score for each possible pair of epochs, batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Step:\n",
    "Modify build_model_2 function so that activation and optimizer becomes parameters to the model create a new empty list to hold the results. Loop over pairs of activation and optimizer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
