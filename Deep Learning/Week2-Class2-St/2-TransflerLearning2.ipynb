{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the VGG16 Network to Train a Deep Learning Network to Identify Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Initiate the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Load the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Change the image to an array by using the img_to_array function\n",
    "Next, we can convert the pixels to a NumPy array so that we can work with it in Keras. We can use the img_to_array() function for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Change the image into four-dimensional form\n",
    "\n",
    "The network expects one or more images as input; that means the input array will need to be 4-dimensional: samples, rows, columns, and channels.\n",
    "\n",
    "We only have one sample (one image). We can reshape the array by calling reshape() and adding the extra dimension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You an also do the same thing as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 Preprocess the image\n",
    "Next, the image pixels need to be prepared in the same way as the ImageNet training data was prepared. Specifically, from the original paper:\n",
    "\n",
    "`The only preprocessing we do is subtracting the mean RGB value, computed on the training set, from each pixel.\n",
    "Preprocess the image using the preprocess_input function`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 Create the `predictor` variable:\n",
    "We can call the `predict()` function on the model in order to get a prediction of the probability of the image belonging to each of the 1000 known object types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 Check the shape of the image. \n",
    "It should be (1,1000). It's 1000 because the ImageNet database has 1000 categories of images. The predictor variable shows the probability of our image being one of those images:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9 Print the top five probabilities of what our image is\n",
    "Use the `decode_predictions` function and pass the function of the predictor variable, `y_pred`, and the number of predictions and corresponding labels to output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10 Put the predictions in a human-readable form. \n",
    "Print the most probable label from the output from the result of the `decode_predictions` function:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
